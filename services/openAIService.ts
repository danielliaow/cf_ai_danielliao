// Simple OpenAI service using environment variables for easy configuration
import { Platform } from 'react-native';

export interface OpenAIMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

export interface OpenAIResponse {
  success: boolean;
  content?: string;
  error?: string;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export class OpenAIService {
  private static readonly API_KEY = process.env.EXPO_PUBLIC_OPENAI_API_KEY;
  private static readonly MODEL = process.env.EXPO_PUBLIC_OPENAI_MODEL || 'gpt-4';
  private static readonly BASE_URL = process.env.EXPO_PUBLIC_OPENAI_BASE_URL || 'https://api.openai.com/v1';

  /**
   * Check if OpenAI is properly configured
   */
  static isConfigured(): boolean {
    const hasApiKey = !!(this.API_KEY && this.API_KEY !== 'your-openai-api-key-here');
    const hasModel = !!this.MODEL;

    if (!hasApiKey) {
      console.warn('‚ö†Ô∏è OpenAI API key not configured. Please set EXPO_PUBLIC_OPENAI_API_KEY in your .env file');
    }

    return hasApiKey && hasModel;
  }

  /**
   * Get current configuration info
   */
  static getConfig(): { model: string; hasApiKey: boolean; baseUrl: string } {
    return {
      model: this.MODEL,
      hasApiKey: !!(this.API_KEY && this.API_KEY !== 'your-openai-api-key-here'),
      baseUrl: this.BASE_URL,
    };
  }

  /**
   * Send a simple chat completion request to OpenAI
   */
  static async chatCompletion(
    messages: OpenAIMessage[],
    options: {
      temperature?: number;
      max_tokens?: number;
      stream?: boolean;
    } = {}
  ): Promise<OpenAIResponse> {
    if (!this.isConfigured()) {
      return {
        success: false,
        error: 'OpenAI not configured. Please set EXPO_PUBLIC_OPENAI_API_KEY in your .env file'
      };
    }

    try {
      console.log('ü§ñ Sending request to OpenAI...');
      console.log('üìù Model:', this.MODEL);
      console.log('üí¨ Messages:', messages.length);

      const response = await fetch(`${this.BASE_URL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.MODEL,
          messages: messages,
          temperature: options.temperature || 0.7,
          max_tokens: options.max_tokens || 1000,
          stream: false, // We'll implement streaming separately if needed
        }),
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        console.error('‚ùå OpenAI API error:', response.status, errorData);

        // Handle specific error cases
        if (response.status === 401) {
          return {
            success: false,
            error: 'Invalid OpenAI API key. Please check EXPO_PUBLIC_OPENAI_API_KEY in your .env file'
          };
        } else if (response.status === 404 && this.MODEL.startsWith('ft:')) {
          return {
            success: false,
            error: `Fine-tuned model "${this.MODEL}" not found. Please check your model ID in EXPO_PUBLIC_OPENAI_MODEL`
          };
        } else if (response.status === 429) {
          return {
            success: false,
            error: 'OpenAI API rate limit exceeded. Please try again later'
          };
        }

        return {
          success: false,
          error: errorData.error?.message || `HTTP ${response.status}: ${response.statusText}`
        };
      }

      const data = await response.json();
      console.log('‚úÖ OpenAI response received');

      if (!data.choices || data.choices.length === 0) {
        return {
          success: false,
          error: 'No response generated by OpenAI'
        };
      }

      return {
        success: true,
        content: data.choices[0].message?.content || '',
        usage: data.usage
      };

    } catch (error) {
      console.error('‚ùå OpenAI service error:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Failed to connect to OpenAI'
      };
    }
  }

  /**
   * Simple chat method for easy use
   */
  static async chat(
    userMessage: string,
    systemPrompt?: string,
    conversationHistory: OpenAIMessage[] = []
  ): Promise<OpenAIResponse> {
    const messages: OpenAIMessage[] = [];

    // Add system prompt if provided
    if (systemPrompt) {
      messages.push({ role: 'system', content: systemPrompt });
    }

    // Add conversation history
    messages.push(...conversationHistory);

    // Add current user message
    messages.push({ role: 'user', content: userMessage });

    return this.chatCompletion(messages);
  }

  /**
   * Chat method optimized for voice conversations
   */
  static async voiceChat(
    userMessage: string,
    conversationHistory: OpenAIMessage[] = []
  ): Promise<OpenAIResponse> {
    const systemPrompt = `You are Embr, a warm and intelligent AI assistant who loves helping people through natural conversation.

Your conversational style:
- Speak naturally like a friendly, knowledgeable friend would
- Keep responses conversational and flowing (1-2 sentences usually)
- Use warm, engaging language with natural speech patterns
- Include subtle conversational fillers like "Well," "You know," "Actually," when appropriate
- Show genuine interest and enthusiasm in your responses
- Avoid robotic or overly formal language - be human-like and relatable
- Use contractions (I'll, you're, that's) to sound more natural
- When excited about something, let that enthusiasm show in your tone

For voice conversations specifically:
- Prioritize spoken clarity over written precision
- Use pauses and natural rhythm in your speech
- If giving complex information, break it into digestible conversational chunks
- Ask follow-up questions to keep the conversation flowing naturally
- Remember you're having a real-time voice chat, not writing an essay

Be the kind of assistant people genuinely enjoy talking to - warm, smart, and authentically helpful.`;

    return this.chat(userMessage, systemPrompt, conversationHistory);
  }

  /**
   * Test the OpenAI connection and model
   */
  static async testConnection(): Promise<OpenAIResponse> {
    const testMessage = "Hello, this is a test message. Please respond with 'Connection test successful' if you receive this.";

    console.log('üß™ Testing OpenAI connection...');
    console.log('üîß Model:', this.MODEL);
    console.log('üîë API Key configured:', !!(this.API_KEY && this.API_KEY !== 'your-openai-api-key-here'));

    const response = await this.chat(testMessage, 'You are a helpful assistant. Please confirm you received the test message.');

    if (response.success) {
      console.log('‚úÖ OpenAI connection test successful');
      console.log('üí∞ Usage:', response.usage);
    } else {
      console.error('‚ùå OpenAI connection test failed:', response.error);
    }

    return response;
  }

  /**
   * Create a system prompt for personalized conversations
   */
  static createPersonalizedSystemPrompt(userContext?: {
    name?: string;
    profession?: string;
    hobbies?: string[];
    communicationStyle?: string;
  }): string {
    let prompt = `You are Embr, a helpful AI assistant. `;

    if (userContext?.name) {
      prompt += `The user's name is ${userContext.name}. `;
    }

    if (userContext?.profession) {
      prompt += `They work as a ${userContext.profession}. `;
    }

    if (userContext?.hobbies && userContext.hobbies.length > 0) {
      prompt += `Their hobbies include ${userContext.hobbies.join(', ')}. `;
    }

    if (userContext?.communicationStyle) {
      prompt += `They prefer ${userContext.communicationStyle} communication. `;
    }

    prompt += `Be helpful, friendly, and adapt your responses to their context and preferences.`;

    return prompt;
  }

  /**
   * Get model information
   */
  static getModelInfo(): {
    model: string;
    isFineTuned: boolean;
    baseModel?: string;
    organization?: string;
    modelId?: string;
  } {
    const isFineTuned = this.MODEL.startsWith('ft:');

    if (isFineTuned) {
      // Parse fine-tuned model ID: ft:base-model:org:name:id
      const parts = this.MODEL.split(':');
      return {
        model: this.MODEL,
        isFineTuned: true,
        baseModel: parts[1],
        organization: parts[2],
        modelId: parts[4],
      };
    }

    return {
      model: this.MODEL,
      isFineTuned: false,
    };
  }
}